---
title: 'Get Streaming Speech'
description: "This API provides real-time text-to-speech conversion using WebSockets. This allows you to send a text message and receive audio data back in real-time."
---

<Note>Endpoint:
`wss://call-dev.smallest.ai/invocations_streaming?token={authorization_token}`</Note>

<Tip>Contact the team at info@smallest.ai for your authorization_token.</Tip>

## Protocol

The WebSocket uses a half-duplex protocol wherein the client sends a json object but receives bytes in return.
The default output audio sample rate is 24000.

## How to use

The client can send messages with text input to the server. The messages can contain the following fields:

```json
{
    "text": "आवाज़ एक बहुत ही बढ़िया text to speech मॉडल है",
    "voice_id": "sarika_north_indian_female",
    "add_wav_header": false,
    "sample_rate": 24000
}
```


<ParamField path="text" type="string">
  Text that needs to be converted to speech
</ParamField>

<ParamField path="voice_id" type="string">
  Name of the voice needed. Please note that the voice_id needs to be sent as a string. Check the section above for example. The only allowed values are - 
    1. sarika_north_indian_female
    <iframe width="500" height="300" src="https://www.youtube.com/embed/tj6IGjw_Wuc?si=SxUDzr_GLgUfwXxk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> 

    2. rakesh_north_indian_male 
    <iframe width="500" height="300" src="https://www.youtube.com/embed/9Mt0qeYW-Zs?si=WBuUAIkGk0tff-OT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    3. chandralekha_bengal_female
    <iframe width="500" height="300" src="https://www.youtube.com/embed/SniAeDlVqFc?si=FZ0cHTRM1EBAqFuZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    4. rustom_bengal_male
    <iframe width="500" height="300" src="https://www.youtube.com/embed/Sjra76bsccQ?si=6gYrN2e5a8dAnSSE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    5. ishwara_south_indian_male
    <iframe width="500" height="300" src="https://www.youtube.com/embed/694VWepnDeE?si=dpXKVIPgiXZD1Iy2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</ParamField>

<ParamField path="add_wav_header" type="bool">
  Whether a wav header is needed by default in the output or not. Default is True.
</ParamField>

<ParamField path="sample_rate" type="int">
  Sample rate needed for output. Default is 24000.
</ParamField>

## Example Code to Use - Python

```python
import json
import wave
import websockets
from pydub import AudioSegment
from datetime import datetime, timezone
from websockets.sync.client import connect

url = 'wss://call-dev.smallest.ai/invocations_streaming?token=<authorization_token>'

payload = {
    'text': 'आवाज़ एक बहुत ही बढ़िया text to speech मॉडल है',
    'voice_id': 'sarika_north_indian_female',
    'add_wav_header': False
}

def encode_audio_common_wav(frame_input, sample_rate=24000, sample_width=2, channels=1):
    """Ensure the WAV file is encoded with standard settings"""
    audio = AudioSegment(
        data=frame_input,
        sample_width=sample_width,
        frame_rate=sample_rate,
        channels=channels
    )

    wav_buf = io.BytesIO()
    audio.export(wav_buf, format="wav")
    # Seek to the beginning of the buffer
    wav_buf.seek(0)
    return wav_buf.read()

def awaaz_streaming():
    first = False
    wav_audio_bytes = b''

    print(f"start_time: {datetime.now(timezone.utc)}")

    try:
        with connect(url) as websocket:
            data = json.dumps(payload)
            websocket.send(data)
            print(f"> {data}")

            try:
                while True:
                    response = websocket.recv()
                    wav_audio_bytes += response
                    if not first:
                        print(f"first response: {datetime.now(timezone.utc)}")
                        first = True
            except websockets.exceptions.ConnectionClosed as e:
                if e.code == 1000:
                    print("Connection closed normally (code 1000).")
                else:
                    print(f"Connection closed with code {e.code}: {e.reason}")
            except Exception as e:
                print(f"Exception occurred: {e}")
            finally:
                print("Saving audio file")
                if not payload['add_wav_header']:
                   wav_audio_bytes = encode_audio_common_wav(wav_audio_bytes)
                with open(f"awaaz_{payload['voice_id']}.wav", "wb") as f:
                    f.write(wav_audio_bytes)
                print("Connection closed")
    except Exception as e:
        print(f"Failed to establish connection: {e}")

if __name__ == "__main__":
    awaaz_streaming()
```

## Example Code to Use - Node

```javascript
const WebSocket = require('websocket').w3cwebsocket;
const fs = require('fs');
const WaveFile = require('wavefile').WaveFile;

// WebSocket URL and payload
const url = 'wss://call-dev.smallest.ai/invocations_streaming?token=<authorization_token>';
const payload = {
    text: 'आवाज़ एक बहुत ही बढ़िया text to speech मॉडल है',
    voice_id: 'sarika_north_indian_female',
    add_wav_header: false
};

// Function to encode PCM data into a WAV file
function encodeAudioCommonWav(frameInput, sampleRate = 24000, sampleWidth = 2, channels = 1) {
    let wav = new WaveFile();
    let bitDepth = sampleWidth * 8;
    wav.fromScratch(channels, sampleRate, bitDepth, frameInput);
    return Buffer.from(wav.toBuffer());
}

// Function to handle streaming and saving the audio file
async function awaazStreaming() {
    let first = false;
    let wavAudioBytes = Buffer.alloc(0);

    if (!payload.add_wav_header) {
        wavAudioBytes = Buffer.concat([wavAudioBytes, encodeAudioCommonWav(wavAudioBytes)]);
    }
    console.log(`start_time: ${new Date().toISOString()}`);

    try {
        const client = new WebSocket(url);

        client.onopen = () => {
            const data = JSON.stringify(payload);
            client.send(data);
            console.log(`> ${data}`);
        };

        client.onmessage = (message) => {
            wavAudioBytes = Buffer.concat([wavAudioBytes, Buffer.from(message.data)]);
            if (!first) {
                console.log(`first response: ${new Date().toISOString()}`);
                first = true;
            }
        };

        client.onclose = (event) => {
            if (event.code === 1000) {
                console.log("Connection closed normally (code 1000).");
            } else {
                console.log(`Connection closed with code ${event.code}: ${event.reason}`);
            }
            saveAudioFile(wavAudioBytes);
            console.log("Connection closed");
        };

        client.onerror = (error) => {
            console.log(`WebSocket error: ${error.message}`);
        };
    } catch (error) {
        console.log(`Failed to establish connection: ${error}`);
    }
}

// Function to save the audio file
function saveAudioFile(wavAudioBytes) {
    console.log("Saving audio file");
    if (!payload.add_wav_header) {
        wavAudioBytes = encodeAudioCommonWav(wavAudioBytes);
    }
    fs.writeFileSync(`awaaz_${payload.voice_id}.wav`, wavAudioBytes);
}

// Run the streaming function
awaazStreaming();
```


